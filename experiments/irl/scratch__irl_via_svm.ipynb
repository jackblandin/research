{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b19238b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Messing around with SVMs and IRL concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6e3bae07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T16:02:48.325664Z",
     "start_time": "2023-03-08T16:02:48.316200Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Add parent directory to current path\n",
    "import os.path\n",
    "import sys\n",
    "p = os.path.abspath('../..')\n",
    "if p not in sys.path:\n",
    "    sys.path.insert(0,p)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from research.ml.svm import SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f158f5ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T16:02:49.014191Z",
     "start_time": "2023-03-08T16:02:48.989231Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'svm.sup_idx_'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]),)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'svm.sup_X_'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.33333333, 0.        , 0.33333333, 0.        , 0.        ,\n",
       "        0.        , 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.        , 0.        , 0.33333333,\n",
       "        0.        , 0.        ],\n",
       "       [0.33333333, 0.33333333, 0.        , 0.33333333, 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.33333333, 0.        , 0.33333333, 0.        , 0.        ,\n",
       "        0.33333333, 0.        ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'svm.sup_y_'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  1, -1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'svm.sup_alphas'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([8.99999849, 8.99999803, 9.00000031, 9.00000077])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x0 = np.array([1/3, 0, 1/3, 0, 0, 0, 1/3])  # a=1,1 (Expert policy)\n",
    "x1 = np.array([1/3, 1/3, 0, 0, 1/3, 0, 0])  # a=0,1\n",
    "x2 = np.array([1/3, 1/3, 0, 1/3, 0, 0, 0])  # a=0,0 (Expert policly if Disparate Impact)\n",
    "x3 = np.array([1/3, 0, 1/3, 0, 0, 1/3, 0])  # a=1,0\n",
    "X = np.zeros((4, 7))\n",
    "X[0] = x0\n",
    "X[1] = x1\n",
    "X[2] = x2\n",
    "X[3] = x3\n",
    "y = np.array([1, 0, 1, 0])  # Only 1 for expert policy\n",
    "\n",
    "svm = SVM()\n",
    "svm.fit(X, y)\n",
    "display('svm.sup_idx_', svm.sup_idx_)\n",
    "display('svm.sup_X_', svm.sup_X_)\n",
    "display('svm.sup_y_', svm.sup_y_)\n",
    "display('svm.sup_alphas', svm.sup_alphas_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc33b2a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c873c1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T19:19:04.390412Z",
     "start_time": "2023-03-07T19:19:04.376508Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -0.,  1., -0.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(np.round(svm.predict_proba(X), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e58bbf55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T19:19:04.657784Z",
     "start_time": "2023-03-07T19:19:04.648035Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.00001581])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm._compute_discriminant(np.array([x3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e9b28af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T19:19:05.041159Z",
     "start_time": "2023-03-07T19:19:05.021927Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.00009674,  6.00004932,  6.00004742,  3.00002302,  3.00002629,\n",
       "        3.00002208,  3.00002535])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0., -0.,  0.,  3., -3., -3.,  3.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In [Abbeel, Ng, 2004] they say \"the vector w^(i) we want is the unit vector\n",
    "orthogonal to the maximum margin separating hyperplane.\" I believe that unit\n",
    "vector is the (dot product? projection?) of svm.sup_X_ and svm.sup_alphas.The\n",
    "reason I think that is because the discriminant for an input point is computed\n",
    "by multiplying sup_X_ by sup_alphas_ by the input point, and then the value of\n",
    "the discriminant determines whether its within the H+/- hyperplane boundary or\n",
    "not. I'm interpreting \"sup_X_\" as \"the points/directions that matter\" (ie the\n",
    "actual support vectors) and \"sup_alphas_\" as \"how much each of those\n",
    "points/directions matter\".\n",
    "\n",
    "Translating this into our IRL problem, the \"sup_X_\" represent \"the policies\n",
    "that matter\" and the \"sup_alphas_\" represent how much each policy matters.\n",
    "\n",
    "So \"points\" are \"policies\", and \"directions/magnitudes\" are \"feature\n",
    "expectations\". So the unit vector orthogonal to the maximum margin separating\n",
    "hyperplane (ie w^(i)) will be a k-length vector (k is size of phi) that, when\n",
    "computed as w^(i)^T dot (some_policy), represents the distance of that policy\n",
    "to the expert policy. That w^(i) also represents the learned reward function.\n",
    "\n",
    "Therefore, our learned reward function should be a k-length vector, and should\n",
    "be obtained from the svm by:\n",
    "```\n",
    "# <1, n_sup_vectors> <n_sup_vectors, k>\n",
    "w = np.dot(svm.sup_alphas_.T, svm.sup_X_)\n",
    "```\n",
    "\"\"\"\n",
    "display(np.dot(svm.sup_alphas_.T, svm.sup_X_))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "If I'm interpreting this right, the w represents the reward function that best\n",
    "separates the expert policy from the non-expert policies. I.e. it yields the\n",
    "largest difference between the expert reward and non-expert rewards. What I'm\n",
    "confused by is that this vector is used to compute the discriminant. So when\n",
    "this vector is multiplied by an input policy, if it's large, then we know the\n",
    "input policy is not the experts. So this is like an inverse reward...\n",
    "\n",
    "Oh wait. When this value is large AND POSITIVE, that means that it's likely\n",
    "the expert's. So need to add in the y part to the discriminant computation.\n",
    "\n",
    "```\n",
    "w = np.dot(svm.sup_alphas.T, (svm.sup_X_ * svm.sup_y_))\n",
    "```\n",
    "\"\"\"\n",
    "sup_X_ = np.array(svm.sup_X_)\n",
    "\n",
    "for i in range(len(svm.sup_y_)):\n",
    "    sup_X_[i] *= svm.sup_y_[i]\n",
    "\n",
    "display(np.round(np.dot(svm.sup_alphas_.T, sup_X_), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ca9968b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T19:19:05.804824Z",
     "start_time": "2023-03-07T19:19:05.796727Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trial 1\n",
    "    When we exclude the 1,0 policy as a training point, we see the following\n",
    "    learned reward values:\n",
    "    \n",
    "        [-0.   , -1.715,  1.715, -0.858, -0.857,  0.   ,  1.715]\n",
    "        \n",
    "    which shows that the 3rd state and last states are equally desirable because\n",
    "    they are able to separate the expert from non-expert policies equally.\n",
    "\n",
    "Trial 2\n",
    "    When we include the 1,0 policy as a negative training point (non-expert),\n",
    "    thereby only getting positive reward when both individuals receive a positive\n",
    "    prediction, we see the following learned rewards:\n",
    "    \n",
    "        [-0. , -1. ,  1. , -0.5, -0.5, -2.5,  3.5]\n",
    "        \n",
    "    Which shows that the 3rd state is no longer considered as desirable, because\n",
    "    now there is a policy that has this state but is not the expert's.\n",
    "\n",
    "Trial 3\n",
    "    When we include the 0,0 policy as a positive training point, thereby\n",
    "    implementing disparate impact as our reward function, we see the following\n",
    "    learned rewards:\n",
    "    \n",
    "        [-0.,  0., -0.,  3., -3., -3.,  3.]\n",
    "        \n",
    "    So it values the final state as the most significant, which makes sense since\n",
    "    we cannot determine the desirability of the intermediate states until the\n",
    "    final state is observed.\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f065c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T19:21:04.718018Z",
     "start_time": "2023-03-07T19:21:04.710761Z"
    }
   },
   "source": [
    "# Full IRL – 03/07/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b9ff4b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T16:13:55.124860Z",
     "start_time": "2023-03-08T16:13:55.114209Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Add parent directory to current path. Needed for research imports.\n",
    "import os.path\n",
    "import sys\n",
    "p = os.path.abspath('../..')\n",
    "if p not in sys.path:\n",
    "    sys.path.insert(0,p)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from research.ml.svm import SVM\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, KFold, RandomizedSearchCV)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "946a48df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T16:12:10.349945Z",
     "start_time": "2023-03-08T16:12:10.256392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23371</th>\n",
       "      <td>41</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>194636</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>99999</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26679</th>\n",
       "      <td>43</td>\n",
       "      <td>Private</td>\n",
       "      <td>397963</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>594</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12591</th>\n",
       "      <td>51</td>\n",
       "      <td>Private</td>\n",
       "      <td>345459</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age     workclass  fnlwgt     education  educational-num  \\\n",
       "23371   41  Self-emp-inc  194636     Bachelors               13   \n",
       "26679   43       Private  397963       HS-grad                9   \n",
       "12591   51       Private  345459  Some-college               10   \n",
       "\n",
       "           marital-status         occupation   relationship   race  gender  \\\n",
       "23371  Married-civ-spouse              Sales        Husband  White    Male   \n",
       "26679            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "12591       Never-married    Exec-managerial      Unmarried  Black  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country income  \n",
       "23371         99999             0              65  United-States   >50K  \n",
       "26679           594             0              16  United-States  <=50K  \n",
       "12591             0             0              40  United-States  <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import adult dataset\n",
    "adult = pd.read_csv('./../../data/adult.csv')\n",
    "adult.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71627ca",
   "metadata": {},
   "source": [
    "### Notes and Assumptions\n",
    "\n",
    "* Meaning of `fnlwgt` column: it is the (estimated) number of people each row in the data represents. I'm removing it for now. Although we may want to consider resampling each row based on its `fnlwgt` value. See what other papers do with this column.\n",
    "* There are 5 possible values for `race`. I'm going to make it binary with `White` vs `Non-White`. Gender only has male and female so leaving this as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1cbf14af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T17:26:55.014235Z",
     "start_time": "2023-03-08T17:26:54.969683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Race'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True     0.855043\n",
       "False    0.144957\n",
       "Name: race, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Gender'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True     0.668482\n",
       "False    0.331518\n",
       "Name: gender, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Income'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.760718\n",
       "True     0.239282\n",
       "Name: income, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = adult.copy()\n",
    "\n",
    "# Transform sensitive attriburtes and target to binary values\n",
    "df['race'] = df['race'] == 'White'\n",
    "df['gender'] = df['gender'] == 'Male'\n",
    "df['income'] = df['income'] == '>50K'\n",
    "display('Race', df['race'].value_counts(1))\n",
    "display('Gender', df['gender'].value_counts(1))\n",
    "display('Income', df['income'].value_counts(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c4d06a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T17:26:55.784962Z",
     "start_time": "2023-03-08T17:26:55.775819Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "feature_types = {\n",
    "    'boolean': [\n",
    "        'race', 'gender',\n",
    "    ],\n",
    "    'categoric': [\n",
    "        'workclass', 'education', 'marital-status', 'occupation',\n",
    "        'relationship', 'native-country',\n",
    "    ],\n",
    "    'continuous': [\n",
    "        'age', 'educational-num', 'capital-gain', 'capital-loss',\n",
    "        'hours-per-week',\n",
    "    ],\n",
    "    'meta': [\n",
    "        'fnlwgt'\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "46267db1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T17:26:56.468822Z",
     "start_time": "2023-03-08T17:26:56.447432Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop meta columns\n",
    "df = df.drop(columns=feature_types['meta'])\n",
    "X = df[feature_types['boolean'] + feature_types['categoric'] + feature_types['continuous']]\n",
    "y = df['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51acb92d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T17:26:57.434594Z",
     "start_time": "2023-03-08T17:26:57.418508Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Helper functions\n",
    "##\n",
    "def train_clf(feature_types, clf_inst, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Create demonstration (X, yhat, y)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_types : dict\n",
    "    clf_inst : sklearn classifier\n",
    "        Unfitted sklearn classifier instance. E.g. `RandomForestClassifier()`.\n",
    "    X_train : pandas.DataFrame\n",
    "    y_train : pandas.Series\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    clf : sklearn classifier\n",
    "        Fitted classifier.\n",
    "    \"\"\"\n",
    "    numeric_trf = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "        ]\n",
    "    )\n",
    "    categoric_trf = Pipeline(\n",
    "        steps=[\n",
    "            (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "            (\"selector\", SelectPercentile(chi2, percentile=50)),\n",
    "        ]\n",
    "    )\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_trf, feature_types['continuous']),\n",
    "            (\"cat\", categoric_trf, feature_types['categoric']),\n",
    "        ]\n",
    "    )\n",
    "    clf = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", clf_inst),\n",
    "        ]\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "    \n",
    "    \n",
    "def generate_demo(clf, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Create demonstration (X, yhat, y) from a fitted classifer `clf`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : fitted sklearn classifier\n",
    "    X_test : pandas.DataFrame\n",
    "    y_test : pandas.Series\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    demo : pandas.DataFrame\n",
    "        Demonstrations. Each demonstration represents an iteration of a\n",
    "        trained classifier and its predictions on a hold-out set. Columns are\n",
    "            **`X` columns : all input columns (i.e. `X`)\n",
    "            yhat : predictions\n",
    "            y : ground truth targets\n",
    "    \"\"\"\n",
    "    yhat = clf.predict(X_test)\n",
    "    demo = pd.DataFrame(X_test)\n",
    "    demo['yhat'] = yhat\n",
    "    demo['y'] = y_test\n",
    "    return demo\n",
    "\n",
    "\n",
    "def feature_exp(demo, z_col):\n",
    "    \"\"\"\n",
    "    Transform demonstrations into feature expectations\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    demo : pandas.DataFrame\n",
    "        Demonstrations. Each demonstration represents an iteration of a\n",
    "        trained classifier and its predictions on a hold-out set. Columns are\n",
    "            **`X` columns : all input columns (i.e. `X`)\n",
    "            yhat : predictions\n",
    "            y : ground truth targets\n",
    "    z_col : str\n",
    "        The column to use for fairness computations. E.g. \"race\".\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    array<float>, len(2)\n",
    "        mu0 : float, range(0,1)\n",
    "            The accuracy feature expectations.\n",
    "        mu1 : float, range(0,1)\n",
    "            The fairness (disparate impact) feature expectations.\n",
    "    \"\"\"\n",
    "    # Accuracy\n",
    "    mu0 = np.mean(demo['yhat'] == demo['y'])\n",
    "    # Disparate Impact\n",
    "    p_yhat_eq_1_giv_z_eq_0 = ((demo['yhat'] == 1) & (demo[z_col] == 0)).mean()\n",
    "    p_yhat_eq_1_giv_z_eq_1 = ((demo['yhat'] == 1) & (demo[z_col] == 1)).mean()\n",
    "    mu1 = 1 - max([\n",
    "        p_yhat_eq_1_giv_z_eq_0 - p_yhat_eq_1_giv_z_eq_1,\n",
    "        p_yhat_eq_1_giv_z_eq_1 - p_yhat_eq_1_giv_z_eq_0,\n",
    "    ])\n",
    "    return np.array([mu0, mu1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b8a4b331",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T17:26:58.055113Z",
     "start_time": "2023-03-08T17:26:58.030479Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split data into two: (X_demo, y_demo), (X_irl_valid, y_irl_valid)\n",
    "- The former is used for generating demonstrations.\n",
    "- The latter is used for computing the error term in the IRL loop.\n",
    "\"\"\"\n",
    "X_demo, X_irl_valid, y_demo, y_irl_valid = train_test_split(\n",
    "    X, y, test_size=.33)\n",
    "\n",
    "del X, y  # Make sure I don't acidentally use these variables later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c72cca43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T17:28:38.439786Z",
     "start_time": "2023-03-08T17:28:23.998505Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staring iteration 1/3\n",
      "\tFitting classifier...\n",
      "\tGenerating demo...\n",
      "\tComputing feature expectations...\n",
      "\tmuE[0]: [0.83965897 0.82269894]\n",
      "Staring iteration 2/3\n",
      "\tFitting classifier...\n",
      "\tGenerating demo...\n",
      "\tComputing feature expectations...\n",
      "\tmuE[1]: [0.84946828 0.82984965]\n",
      "Staring iteration 3/3\n",
      "\tFitting classifier...\n",
      "\tGenerating demo...\n",
      "\tComputing feature expectations...\n",
      "\tmuE[2]: [0.85038504 0.81949028]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.83965897, 0.82269894],\n",
       "       [0.84946828, 0.82984965],\n",
       "       [0.85038504, 0.81949028]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = 3  # Number of demonstrations to generate\n",
    "muE = np.zeros((m, 2))  # expert demo feature expectations\n",
    "\n",
    "# Generate demonstrations (populate muE)\n",
    "k_fold = KFold(m)\n",
    "for k, (train, test) in enumerate(k_fold.split(X_demo, y_demo)):\n",
    "    print(f\"Staring iteration {k+1}/{m}\")\n",
    "    X_train, y_train = X_demo.iloc[train], y_demo.iloc[train]\n",
    "    X_test, y_test = X_demo.iloc[test], y_demo.iloc[test]\n",
    "    print('\\tFitting classifier...')\n",
    "    clf = train_clf(feature_types, RandomForestClassifier(), X_train, y_train)\n",
    "    print('\\tGenerating demo...')\n",
    "    demo = generate_demo(clf, X_test, y_test)\n",
    "    print('\\tComputing feature expectations...')\n",
    "    muE[k] = feature_exp(demo, z_col='race')\n",
    "    print(f\"\\tmuE[{k}]: {muE[k]}\")\n",
    "    \n",
    "display(muE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "47f1cdb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T17:28:58.600393Z",
     "start_time": "2023-03-08T17:28:58.512291Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staring iteration 1/1\n",
      "\tFitting classifier...\n",
      "\tGenerating demo...\n",
      "\tComputing feature expectations...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.49541624, 0.65367164])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate initial policy(s)\n",
    "n_init_policies = 1\n",
    "mu = []\n",
    "\n",
    "for i in range(n_init_policies):\n",
    "    print(f\"Staring iteration {i+1}/{n_init_policies}\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_demo, y_demo, test_size=.33)\n",
    "    print('\\tFitting classifier...')\n",
    "    dummy_clf = DummyClassifier(strategy=\"uniform\")\n",
    "    clf = train_clf(feature_types, dummy_clf, X_train, y_train)\n",
    "    print('\\tGenerating demo...')\n",
    "    demo = generate_demo(clf, X_test, y_test)\n",
    "    print('\\tComputing feature expectations...')\n",
    "    mu.append(feature_exp(demo, z_col='race'))\n",
    "    \n",
    "display(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1eeca6db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T17:29:07.373127Z",
     "start_time": "2023-03-08T17:29:07.362259Z"
    }
   },
   "outputs": [],
   "source": [
    "def irl_error(w, muE, muj):\n",
    "    \"\"\"\n",
    "    Computes t[i] = wT(muE-mu[j])\n",
    "    \"\"\"\n",
    "    mu_delta = muE.mean(axis=0) - muj.mean(axis=0)\n",
    "    err = np.dot(w, mu_delta)\n",
    "    return err, mu_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "46321421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T17:56:28.916466Z",
     "start_time": "2023-03-08T17:56:28.908230Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics         import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def custom_reward_function(y, y_pred):\n",
    "    # Only care about accuracy\n",
    "    acc = np.mean(y == y_pred)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def learn_policy(weights, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Compute a policy (classifier) from a set of weights. The weights come from\n",
    "    the SVM classifier used to distinguish the expert demonstrations from the\n",
    "    learned policies.\n",
    "    \n",
    "    weights : array<float>\n",
    "        Weights from SVM classifier.\n",
    "    X_train : pandas.DataFrame\n",
    "    y_train : pandas.Series\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    clf_pol : sklearn compatible classifier\n",
    "    \"\"\"\n",
    "    custom_scorer = make_scorer(\n",
    "        custom_reward_function, greater_is_better=True)\n",
    "    param_grid = {\n",
    "        'max_depth': [20, 100],\n",
    "        'max_features': [2, 3],\n",
    "        'min_samples_leaf': [1, 5],\n",
    "        'min_samples_split': [2, 8],\n",
    "        'n_estimators': [10, 100]\n",
    "    }\n",
    "    rf = RandomForestClassifier()\n",
    "    clf_pol = GridSearchCV(\n",
    "        estimator=rf, param_grid=param_grid, cv=3, scoring=custom_scorer)\n",
    "    clf_pol = train_clf(feature_types, clf_pol, X_train, y_train)\n",
    "    return clf_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "16b2354a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T18:09:21.782476Z",
     "start_time": "2023-03-08T18:07:36.364934Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 1/5 ...\n",
      "\tt[i] = -0.12 \t weights[0] = [4.681 2.299]\n",
      "Starting iteration 2/5 ...\n",
      "\tt[i] = 3.24 \t weights[1] = [  54.541 -108.531]\n",
      "Starting iteration 3/5 ...\n",
      "\tt[i] = 2.88 \t weights[2] = [  59.344 -107.733]\n",
      "Starting iteration 4/5 ...\n",
      "\tt[i] = 2.87 \t weights[3] = [  57.697 -104.954]\n",
      "Starting iteration 5/5 ...\n",
      "\tt[i] = 3.32 \t weights[4] = [  64.085 -116.052]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run IRL loop.\n",
    "Create a clf dataset where inputs are feature expectations and outputs are\n",
    "whether the policy is expert or learned through IRL iterations. Then train an\n",
    "SVM classifier on this dataset. Then extract the weights of the svm and use\n",
    "them as the weights for the \"reward\" function. Then use this reward function\n",
    "to learn a policy (classifier). Then compute the feature expectations from\n",
    "this classifer on the irl hold-out set. Then compute the error between the\n",
    "feature expectations of this learned clf and the demonstration feature exp. If\n",
    "this error is less than epsilon, stop. The reward function is the final set of\n",
    "weights.\n",
    "\"\"\"\n",
    "X_irl_exp = pd.DataFrame(muE, columns=['acc', 'disp_imp'])\n",
    "y_irl_exp = pd.Series(np.ones(m), dtype=bool)\n",
    "X_irl_learn = pd.DataFrame(mu, columns=['acc', 'disp_imp'])\n",
    "y_irl_learn = pd.Series(np.zeros(len(mu)), dtype=bool)\n",
    "X_irl = pd.concat([X_irl_exp, X_irl_learn], axis=0)\n",
    "y_irl = pd.concat([y_irl_exp, y_irl_learn], axis=0).astype(int)\n",
    "\n",
    "epsilon = .05\n",
    "t = []  # Errors for each iteration\n",
    "weights = []\n",
    "i = 0\n",
    "max_iter = 5\n",
    "while True:\n",
    "    print(f\"Starting iteration {i+1}/{max_iter} ...\")\n",
    "    \n",
    "    # Train SVM classifier\n",
    "    svm = SVM().fit(X_irl, y_irl)\n",
    "    \n",
    "    # Extract the weights from the SVM classifier\n",
    "    wi = svm.weights()\n",
    "    weights.append(wi)\n",
    "    \n",
    "    # TODO: Learn a policy (clf) from the reward (svm weights)\n",
    "    pol_clf = learn_policy(weights, X_demo.iloc[0:10_000], y_demo.iloc[0:10_000])\n",
    "    \n",
    "    # Compute feature expectations of the learned policy\n",
    "    demo = generate_demo(pol_clf, X_irl_valid, y_irl_valid)\n",
    "    muj = feature_exp(demo, z_col='race')\n",
    "    \n",
    "    # Append policy's feature expectations to irl clf dataset\n",
    "    X_irl_learn_i = pd.DataFrame(np.array([muj]), columns=['acc', 'disp_imp'])\n",
    "    y_irl_learn_i = pd.Series(np.zeros(1), dtype=int)\n",
    "    X_irl = pd.concat([X_irl, X_irl_learn_i], axis=0)\n",
    "    y_irl = pd.concat([y_irl, y_irl_learn_i], axis=0)\n",
    "    \n",
    "    # Compute error of the learned policy: t[i] = wT(muE-mu[j])\n",
    "    ti, mu_delta = irl_error(wi, muE, muj)\n",
    "    t.append(ti)\n",
    "    print(f\"\\tt[i] = {t[i]:.2f} \\t weights[{i}] = {np.round(weights[i], 3)}\")\n",
    "    \n",
    "#     if ti < epsilon or i >= max_iter - 1:\n",
    "    if i >= max_iter - 1:\n",
    "        break\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "# The weights should converge towards [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c262fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "355.753662109375px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
